# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/topo_solvers/7_trainable_topo_solver.ipynb (unless otherwise specified).

__all__ = ['TrainModule', 'TopoSolver', 'TrivialSolver', 'SIMPIterator', 'SIMP', 'OracleSolver', 'TrainableTopoSolver']

# Internal Cell
import torch

# Internal Cell
class EvalModule:
    """
    A class that contains methods for the evaluation of topo solvers.
    """

    @staticmethod
    def _push_to_device(solutions, device):
        for solution in solutions:
            solution.device = device


    @staticmethod
    @torch.no_grad()
    def _run_epoch(topo_solver, dataloader, criteria):
        criteria_dict = defaultdict(list)

        for problems_or_solutions, gt_solutions in dataloader:
            EvalModule._push_to_device(gt_solutions, device=topo_solver.device)
            solutions = topo_solver(problems_or_solutions, eval_mode=True)

            assert solutions[0].θ.device == gt_solutions[0].θ.device, f"EvalModule: {solutions[0].θ.device=}, but {gt_solutions[0].θ.device=}."

            for criterion in criteria:
                criterion_values = criterion(solutions, gt_solutions, binary=True)
                criterion_values = list(criterion_values.detach().cpu().numpy())
                criteria_dict[criterion.name] += criterion_values

            for criterion in criteria:
                criteria_dict[criterion.name] = list(np.float_(criteria_dict[criterion.name]))

        return criteria_dict


    @staticmethod
    @torch.no_grad()
    def get_first_solutions(topo_solver, n_solutions, dataloader):
        """
        Returns the first `n_solutions` solutions obtained via the topo_solver from problems from the dataloader.

        Returns
        -------
        list
        """
        return_solutions = []

        for problems_or_solutions, gt_solutions in dataloader:
            EvalModule._push_to_device(gt_solutions, device=topo_solver.device)
            solutions = topo_solver(problems_or_solutions, eval_mode=True)

            for solution in solutions:
                return_solutions.append(solution)
                if len(return_solutions) >= n_solutions:
                    return return_solutions

        return return_solutions


    @staticmethod
    def __call__(topo_solver, criteria, dataloader):
        """
        Evalate criteria with outputs from the topo solver.

        Returns
        -------
        collections.defaultdict
        """
        criteria_dict = EvalModule._run_epoch(
            topo_solver=topo_solver,
            dataloader=dataloader,
            criteria=criteria,
        )
        return criteria_dict

# Internal Cell
import copy
import time
import torch
import warnings
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

from .utils import create_dir, save_dict_as_txt, cast_to_solutions

# Internal Cell
class TrainModuleVerboseUtils:
    @staticmethod
    def print_current_losses(topo_solver_logs):
        logs = topo_solver_logs
        train_epoch    = logs["train_epochs"][-1]
        train_loss     = logs['train_losses'][-1]
        train_loss_std = logs['train_losses_std'][-1]
        print(f"Train epoch: {train_epoch}. Train loss: {train_loss:.2}±{train_loss_std:.2}.")
        if "val_losses" in logs:
            val_epoch    = logs["val_epochs"][-1]
            val_loss     = logs['val_losses'][-1]
            val_loss_std = logs['val_losses_std'][-1]
            print(f'Valid epoch: {val_epoch}. Valid loss: {val_loss:.2}±{val_loss_std:.2}.')


    @staticmethod
    def plot_train_and_val_losses(topo_solver_logs):
        logs = topo_solver_logs
        assert len(logs['train_epochs']) == len(logs['train_losses']) == len(topo_solver_logs['train_losses_std']), "Training loss log inconsistent."
        assert len(logs['val_epochs'])   == len(logs['val_losses'])   == len(topo_solver_logs['val_losses_std']), "Validation loss log inconsistent."
        fig, axes = plt.subplots(figsize=(7, 3), dpi=200, sharex=False)
        plot_curve(
            x=logs['train_epochs'],
            y=logs['train_losses'],
            y_std=logs['train_losses_std'],
            label="Training loss",
            axis=axes,
            show_all_xticks=False
        )
        plot_curve(
            x=logs['val_epochs'],
            y=logs['val_losses'],
            y_std=logs['val_losses_std'],
            label="Validation loss",
            axis=axes,
            show_all_xticks=False
        )
        plt.legend()
        plt.show()

# Internal Cell
class EpochLossGetter:
    def __init__(self, topo_solver):
        self.solver = topo_solver
        self.model = self.solver.model if hasattr(self.solver, 'model') else None
        self.criterion = self.solver.criterion  if hasattr(self.solver, 'criterion') else None
        self.optimizer = self.solver.optimizer if hasattr(self.solver, 'optimizer') else None
        self._check_attr()


    def _push_to_device(self, solutions):
        for solution in solutions:
            solution.device = self.solver.device


    def _check_attr(self):
        if self.model is None:
            raise AttributeError("TrainModule cannot train w/o a model!")
        if not self.solver.trainable:
            raise AttributeError(f"Topo solver `{self.solver.name}` is not trainable.")
        if self.criterion is None:
            raise AttributeError("TrainModule cannot find a criterion!")


    def _run_batch(self, problems_or_solutions, gt_solutions, train):
        self._push_to_device(gt_solutions)
        solutions = self.solver(problems_or_solutions, eval_mode=not train)
        losses = self.solver.criterion(solutions, gt_solutions, binary=False)
        loss = losses.mean()
        if train:
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
        losses = list(losses.detach().cpu().numpy().astype(np.float64))
        return losses


    def __call__(self, dataloader, train):
        if train:
            self.model.train()
        else:
            self.model.eval()
        losses = []
        for problems_or_solutions, gt_solutions in dataloader:
            losses += self._run_batch(problems_or_solutions=problems_or_solutions, gt_solutions=gt_solutions, train=train)
        self.model.eval()
        return np.mean(losses), np.std(losses)

# Cell
class TrainModule:
    """
    A class that contains methods for the training of topo solvers.

    Parameters
    ----------
    topo_solver : dl4to.TopoSolver
        The trainable topo solver that should be trained.
    """
    def __init__(self, topo_solver):
        self.solver = topo_solver
        self.epoch_module = EpochLossGetter(self.solver)


    def _train_epoch(self, dataloader, epoch):
        train_loss, train_loss_std = self.epoch_module(dataloader=dataloader, train=True)
        self.solver.logs['train_epochs'].append(epoch)
        self.solver.logs['train_losses'].append(train_loss)
        self.solver.logs['train_losses_std'].append(train_loss_std)


    def _eval_epoch(self, dataloader, epoch, verbose):
        val_loss, val_loss_std = self.epoch_module(dataloader=dataloader, train=False)
        self.solver.logs['val_epochs'].append(epoch)
        self.solver.logs['val_losses'].append(val_loss)
        self.solver.logs['val_losses_std'].append(val_loss_std)

        if verbose:
            TrainModuleVerboseUtils.print_current_losses(topo_solver_logs=self.solver.logs)


    def _write_solver_to_disc(self, dir_path, prefix, tick):
        self.solver.logs['duration'] = time.time() - tick
        torch.save(self.solver, f'{dir_path}/{prefix}_solver.pt')
        save_dict_as_txt(self.solver.logs, dir_path=dir_path, file_name=f'{prefix}_logs')


    def _write_solver_to_disc_if_best_yet(self, dir_path, tick):
        val_losses = self.solver.logs['val_losses']
        val_loss = val_losses[-1]
        best_val_loss = min(val_losses)
        if val_loss > best_val_loss:
            return best_val_loss
        self._write_solver_to_disc(dir_path=dir_path, prefix="best", tick=tick)
        return val_loss


    def _create_folder_and_save_topo_solver_args(self, root, epochs, patience):
        dir_path = create_dir(name=f"train_results", path=root, prepend_date=False)
        my_dict = {
            'root': root,
            'epochs': epochs,
            'patience': patience,
        }
        args_dict = self.solver.get_args_as_dict()
        args_dict = {**args_dict, **my_dict}
        save_dict_as_txt(my_dict=args_dict, dir_path=dir_path, file_name="solver_description")

        return dir_path


    def _get_best_epoch(self):
        val_losses = self.solver.logs['val_losses']
        val_epochs = self.solver.logs['val_epochs']
        assert len(val_losses) == len(val_epochs), "TrainModule: len(val_losses) != len(val_epochs)"
        best_val_loss_idx = np.argmin(val_losses)
        return val_epochs[best_val_loss_idx]


    def _input_check(self, dataloader_val, validation_interval, patience):
        if dataloader_val is not None:
            return
        if validation_interval is not None:
            raise ValueError("You can not validate without a dataloader_val. Set validation_interval=None or add dataloader_val.")
        if patience != "inf":
            raise ValueError("patience != 'inf' requires dataloader_val != None.")


    def __call__(
        self, root, dataloader_train,
        dataloader_val=None, epochs=100,
        validation_interval=10, verbose=True,
        patience=None):
        """
        Run the training for the topo solver.

        Parameters
        -------
        root : str
            The directory where the training results should be saved.
        dataloader_train : torch.utils.data.Dataloader
            The dataloader that contains the training data.
        dataloader_val : torch.utils.data.Dataloader
            The dataloader that contains the validation data.
        epochs : int
            The maximal number of training epochs.
        validation_interval : int
            The number of epochs after which a validation step is performed and printed.
        verbose : bool
            Whether to print information on the current training status, like the current loss and epoch.
        patience : int
            If the validation score does not improve for `patience` epochs in a row, then the training is stopped and the best model is used.
        """
        if patience is None:
            patience = "inf"
        self._input_check(dataloader_val, validation_interval, patience)
        dir_path = self._create_folder_and_save_topo_solver_args(root, epochs, patience)
        tick = time.time()

        for epoch in range(epochs):
            self._train_epoch(dataloader_train, epoch)
            validation_free_epoch = (validation_interval is None) or ((epoch % validation_interval != 0) and (epoch != epochs - 1))
            if validation_free_epoch:
                continue
            self._eval_epoch(dataloader_val, epoch, verbose)
            self._write_solver_to_disc_if_best_yet(dir_path, tick)
            if patience != "inf":
                we_have_lost_hope = epoch > self._get_best_epoch() + patience
                if we_have_lost_hope:
                    break
        self._write_solver_to_disc(dir_path=dir_path, prefix="last", tick=tick)
        if verbose:
            TrainModuleVerboseUtils.plot_train_and_val_losses(topo_solver_logs=self.solver.logs)
        print(f'Finished training after {epoch + 1} epochs.\n')

# Internal Cell
import copy
import torch
from typing import Union

from .solution import Solution
from .utils import get_dataloader, cast_to_solutions, save_dict_as_txt, create_dir

# Cell
class TopoSolver:
    """
    A parent class that inherits all kinds of topo solvers, i.e., algorithms that solve the topology optimization task.
    """
    def __init__(self,
                 device:str='cpu', # The device of the topo solver. Can bei either "cpu" or "cuda".
                 name:str=None, # The name of the topo solver.
                 trainable:bool=False, # Whether the topo solver is trainable.
                 differentiable:bool=False # Whether the topo solver is differentiable.
                ):
        self._device = device
        self.name = name
        self._trainable = trainable
        self._differentiable = differentiable


    @property
    def device(self):
        return self._device


    @device.setter
    def device(self, device):
        self._device = device


    def to(self,
           device:str # The device of the topo solver. Can bei either "cpu" or "cuda".
          ):
        """
        Move the topo solver to `device`.
        """
        self.device = device


    def cuda(self):
        """
        Move the topo solver to `cuda`.
        """
        self.to('cuda')


    def cpu(self):
        """
        Move the topo solver to `cpu`.
        """
        self.to('cpu')


    @property
    def trainable(self):
        return self._trainable


    @property
    def differentiable(self):
        return self._differentiable


    def clone(self):
        """
        Return a `dl4to.topo_solvers.TopoSolver` object, which is clone of the current topo solver.
        """
        return copy.deepcopy(self)


    def _if_tuple_cast_to_list(self, problems_or_solutions):
        if type(problems_or_solutions) is tuple:
            problems_or_solutions = list(problems_or_solutions)
        return problems_or_solutions


    def _prepare_input_in_call(self, problems_or_solutions):
        problems_or_solutions = self._if_tuple_cast_to_list(problems_or_solutions)
        was_list = True

        if type(problems_or_solutions) != list:
            problems_or_solutions = [problems_or_solutions]
            was_list = False

        solutions = cast_to_solutions(problems_or_solutions)
        return solutions, was_list


    def _get_new_solutions(self, solutions, eval_mode):
        raise NotImplementedError("Must be overridden.")


    def __call__(self,
                 problems_or_solutions:list, # A list containing problem and solution objects.
                 eval_mode:bool=True # Determines whether to calculate gradients for the backwards pass or not. If `True`, then no gradients are calculated.
                ):
        """
        Perform a forward pass of the topo solver. Expects a list of problems or solutions.
        Returns a `dl4to.solution.Solution` object or a list of solutions, if the input was also a list.
        """
        solutions, was_list = self._prepare_input_in_call(problems_or_solutions)
        solutions = self._get_new_solutions(solutions, eval_mode)

        if was_list:
            return solutions
        assert len(solutions) == 1
        return solutions[0]


    def eval(self,
             root:str, # The root directory where the evaluation results are saved.
             criteria:list, # A list of `dl4to.criteria.Criterion` objects that are used for the evaluation.
             dataloader:torch.utils.data.DataLoader # The dataloader that is used for retrieving the validation data.
            ):
        """
        Evalate criteria with outputs from the topo solver. Returns a `collections.defaultdict` dictionary.
        """
        dir_path = create_dir(name=f"eval_on_{dataloader.dataset.name}", path=root, prepend_date=False)

        logs = EvalModule()(
            topo_solver=self,
            criteria=criteria,
            dataloader=dataloader
        )

        save_dict_as_txt(my_dict=logs, dir_path=dir_path, file_name="eval_logs")
        return logs


    def plot_first_solutions_from_dataloader(
        self,
        root:str, # The root where the plots should be saved.
        n_plots:int, # The number of solutions to plot.
        dataloader:torch.utils.data.DataLoader, # The dataloader that is used to obtain the data.
        camera_position:Union[tuple,list]=(0,.1,.12), # x, y, and z coordinates of the camera position.
        export_png:bool=True, # Whether the figure is exported and saved as a png file, in addition to the standard html format.
    ):
        """
        Saves `n_plots` plots of solutions obtained via the topo_solver from problems from the dataloader.
        """
        dir_path = create_dir(name=f"eval_on_{dataloader.dataset.name}", path=root, prepend_date=False)

        solutions = EvalModule.get_first_solutions(
            topo_solver=self,
            n_solutions=n_plots,
            dataloader=dataloader,
        )

        for i, solution in enumerate(solutions):
            torch.save(solution, f"{dir_path}/solution_{i}.pt")

            solution.plot(
                binary=True,
                solve_pde=False,
                display=False,
                file_path=f"{dir_path}/{i}",
                camera_position=camera_position,
                show_colorbar=False,
                export_png=export_png
            )

# Internal Cell
import os
import torch

from .topo_solvers import TopoSolver
from .solution import Solution

# Cell
class TrivialSolver(TopoSolver):
    """
    A topo solver that returns the trivial solution for a problem object.

    Parameters
    ----------
    θ_default : float
        The factor with which the density of the trivial solutions should be multiplied before being returned in the call.
    device : str
        The device of the topo solver. Possible options are "cpu" and "cuda".
    """
    def __init__(self, θ_default=1., device='cpu'):
        super().__init__(device=device)
        self.θ_default = θ_default


    def _get_name(self):
        return "TrivialSolver"


    def _get_new_solution(self, solution):
        if hasattr(solution, 'problem'):
            problem = solution.problem
        else:
            problem = solution

        θ = self.θ_default * torch.ones(1, *problem.shape, device=self.device, dtype=solution.dtype)
        return Solution(problem, θ)


    def _get_new_solutions(self, solutions, eval_mode):
        solutions = [self._get_new_solution(solution) for solution in solutions]
        return solutions

# Cell
import time
import torch
from collections import defaultdict

from .solution import Solution
from .criteria import VolumeFraction, Binariness

# Cell
class SIMPIterator:
    """
    Performs the actual SIMP optimization.
    """
    def __init__(
        self,
        problem:"dl4to.problem.Problem", # The problem that should be solved by SIMP.
        criterion:"dl4to.criteria.Criterion", # The objective function that should be optimized for in the optimization process.
        density_representer:"dl4to.density_representers.DensityRepresenter", # The density representer that is used for the latent density representation. The density representer also performs the projection, smoothing and filtering.
        lr:float, # The learning rate of the `torch.optim.Adam` optimizer.
        binarizer_steepening_factor:float # The factor at which the binarizer should be steepened in each iteration. E.g.,a value of 1.1 corresponds to a steepening of 10% per iteration.
    ):
        self.lr = lr
        self.logs = defaultdict(list)
        self.binarizer_steepening_factor = binarizer_steepening_factor
        self.problem = problem

        self.criterion = criterion
        self.volume_crit = VolumeFraction()
        self.binariness_crit = Binariness()
        self.density_representer = density_representer
        self.optimizer = torch.optim.Adam(self.density_representer.parameters(), lr=self.lr)


    def _extend_logs(self, solution, loss, volume, tick, σ_vm):
        self.logs["losses"].append(loss.item())
        self.logs["volumes"].append(volume.item())
        self.logs["durations"].append(time.time() - tick)
        self.logs["binarinesses"].append(self.binariness_crit([solution]))
        self.logs["relative_max_σ_vm"].append(σ_vm.max().item() / self.problem.σ_ys)


    def _perform_optimizer_step(self, loss):
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()


    def __call__(self,
                 p:float # The SIMP exponent
                ):
        """
        Creates the SIMP solution objects, solves the PDE and communicates with the density representer.
        Returns a `dl4to.solution.Solution` object.
        """
        tick = time.time()
        solution = Solution(
            problem=self.problem,
            θ=self.density_representer(),
        )

        u, σ, σ_vm = solution.solve_pde(p=p)
        loss = self.criterion([solution])
        volume = self.volume_crit([solution])

        self._perform_optimizer_step(loss)
        solution.θ = self.density_representer()
        self.density_representer.steepen_binarizer(self.binarizer_steepening_factor)

        self._extend_logs(solution, loss, volume, tick, σ_vm)
        solution.logs = self.logs

        return solution

# Cell
import torch
import numpy as np
from tqdm import tqdm

from .topo_solvers import TopoSolver, SIMPIterator
from .density_representers import FilteringDensityRepresenter

# Cell
class SIMP(TopoSolver):
    """
    A topo solver that performs topology optimization with the "Solid Isotropic Material with Penalization" (SIMP) method.
    """
    def __init__(
        self,
        criterion:"dl4to.criteria.Criterion", # The objective function that should be optimized for in the optimization process.
        p:float=3., # The SIMP exponent to discourage non-binary densities. The default value is `p=3`, which is the standard value in the literature.
        n_iterations:int=50, # The number of SIMP iterations that should be performed.
        verbose:bool=True, # Whether to give the user feedback on the current status of the optimization.
        lr:float=3e-2, # The learning rate of the `torch.optim.Adam` optimizer.
        binarizer_steepening_factor:float=1., # The factor at which the binarizer should be steepened in each iteration. E.g.,a value of 1.1 corresponds to a steepening of 10% per iteration.
        density_representer:"dl4to.density_representers.DensityRepresenter"=FilteringDensityRepresenter(), # The density representer that is used for the latent density representation. The density representer also performs the projection, smoothing and filtering.
        return_intermediate_solutions:bool=False # Whether intermediate SIMP solutions should be returned or only the final solution of the optimization process.
    ):
        super().__init__(device="cpu", name="SIMP")
        self.p = p
        self.n_iterations = n_iterations
        self.verbose = verbose
        self.criterion = criterion
        self.return_intermediate_solutions = return_intermediate_solutions
        self.density_representer = density_representer
        self.binarizer_steepening_factor = binarizer_steepening_factor
        self.lr = lr
        self.criterion = criterion


    def _run_iterations(self, simp_iterator):
        solutions = []
        iters = range(self.n_iterations)
        if self.verbose:
            iters = tqdm(iters)

        for i in iters:
            solution = simp_iterator(p=self.p)
            if self.return_intermediate_solutions:
                solutions.append(solution)
        if self.return_intermediate_solutions:
            return solutions
        return solution


    def reset(self):
        self.density_representer.reset_binarizer()


    def _get_new_simp_iterator(self, solution, density_representer):
        simp_iterator = SIMPIterator(
            problem=solution.problem,
            criterion=self.criterion,
            density_representer=self.density_representer,
            lr=self.lr,
            binarizer_steepening_factor=self.binarizer_steepening_factor
        )
        return simp_iterator


    def _get_new_solution(self, solution):
        self.density_representer.problem = solution.problem
        simp_iterator = self._get_new_simp_iterator(solution, self.density_representer)
        solution = self._run_iterations(simp_iterator)
        return solution


    def _get_new_solutions(self, solutions, density_representers):
        solutions, density_representers = self._check_and_preprocess_inputs_for_get_new_solutions(solutions, density_representers)
        simp_solutions = []
        for solution in solutions:
            if self.return_intermediate_solutions:
                simp_solutions.extend([self._get_new_solution(solution)])
            else:
                simp_solutions.append(self._get_new_solution(solution))
        return simp_solutions


    def _check_and_preprocess_inputs_for_get_new_solutions(self, solutions, density_representers):
        if type(density_representers) != list:
            density_representers = [density_representers]

        if len(solutions) == len(density_representers):
            return solutions, density_representers
        raise ValueError("SIMP: len(solutions) != len(density_representers)")

# Internal Cell
import os
import torch
from collections import defaultdict

from .topo_solvers import TopoSolver
from .utils import get_dataloader, cast_to_problems

# Cell
class OracleSolver(TopoSolver):
    """
    A topo solver that gets a topo dataset of problems and solutions and returns the ground truth solution for any given problem object from the dataset.
    """
    def __init__(self,
                 dataset:"dl4to.dataset.TopoDataset", # The dataset which is used to look for the given problem and return the assoziated ground truth solution.
                 device:str='cpu' # The device of the topo solver. Possible options are "cpu" and "cuda".
                ):
        super().__init__(device=device, name="OracleSolver")
        self.logs = defaultdict(list)
        self.dataset = dataset


    def _get_new_solutions(self, solutions, eval_mode):
        problems = cast_to_problems(solutions)

        problems_in_dataset = self.dataset.get_problems()
        problem_indices = [problems_in_dataset.index(problem) for problem in problems]

        gt_solutions = [self.dataset[i][1] for i in problem_indices]
        return gt_solutions

# Internal Cell
import json
import torch
import warnings
from copy import deepcopy
from collections import defaultdict

from .utils import get_dataloader
from .preprocessing import TrivialPreprocessing
from .topo_solvers import TopoSolver, TrainModule

# Cell
class TrainableTopoSolver(TopoSolver):
    """
    A topo solver that is trainable and can be used for learned topology optimization.
    """
    def __init__(
        self,
        criterion:"dl4to.criteria.Criterion", # The loss criterion that should be used for the training.
        model:torch.nn.Module, # A PyTorch neural network. Make sure that the input and output dimensions are correct.
        optimizer:torch.optim.Optimizer, # A PyTorch optimizer, for instance torch.optim.Adam. Make sure to set `params=model.parameters()` if you want to use the optimizer to train the neural network.
        preprocessing:"dl4to.preprocessing.Preprocessing"=TrivialPreprocessing(), # The preprocessing that should be used in the pipeline.
        name:str=None # The name of the topo solver.
    ):
        device = next(model.parameters()).device
        super().__init__(
            device=device,
            name=name,
            trainable=True,
            differentiable=True
        )

        self.criterion = criterion
        self.model = model
        self.model.eval()
        self.optimizer = optimizer
        self.preprocessing = preprocessing

        self.logs = defaultdict(list)
        self._train_module = TrainModule(self)


    @property
    def device(self):
        return self._device


    @device.setter
    def device(self, device):
        self._device = device
        self.model.to(device)


    def _get_copy_without_cluttering_entries(self, my_dict):
        internal_dict_wo_model = {}
        for key, value in my_dict.items():
            if key not in {"model", "optimizer", "train_module"}:
                if hasattr(value, 'name'):
                    internal_dict_wo_model[key] = value.name
                else:
                    internal_dict_wo_model[key] = value
        return internal_dict_wo_model


    def get_args_as_dict(self):
        """
        Returns basic properties and arguments of the topo solver as a dictionary.
        """
        internal_dict_wo_model = self._get_copy_without_cluttering_entries(self.__dict__)
        internal_dict_wo_model = {key: str(value) for key, value in internal_dict_wo_model.items()}
        return {'solver_name': self.name, **internal_dict_wo_model}


    def _postprocess_model_outputs(self, model_outputs, solutions):
        new_solutions = []
        for model_output, solution in zip(model_outputs, solutions):
            solution = Solution(problem=solution.problem, θ=model_output)
            new_solutions.append(solution)
        return new_solutions


    def _get_new_solutions(self, solutions, eval_mode):
        model_inputs_list = [self.preprocessing(solution) for solution in solutions]
        model_inputs = torch.cat(model_inputs_list, dim=0).to(self.device)
        if eval_mode:
            self.model.eval()
        model_outputs = self.model(model_inputs)
        solutions = self._postprocess_model_outputs(model_outputs, solutions)
        return solutions


    def train(self,
              root:str, # The directory where the training results should be saved.
              dataloader_train:torch.utils.data.DataLoader, # The dataloader that contains the training data.
              dataloader_val:torch.utils.data.DataLoader=None, # The dataloader that contains the validation data.
              epochs:int=100, # The maximal number of training epochs.
              validation_interval:int=10, # The number of epochs after which a validation step is performed and printed.
              verbose:bool=True, # Whether to print information on the current training status, like the current loss and epoch.
              patience:bool=None # If the validation score does not improve for `patience` epochs in a row, then the training is stopped and the best model is used.
             ):
        """
        Run the training for the topo solver.
        """
        self._train_module(
            root=root,
            dataloader_train=dataloader_train,
            dataloader_val=dataloader_val,
            epochs=epochs,
            validation_interval=validation_interval,
            verbose=verbose,
            patience=patience,
        )